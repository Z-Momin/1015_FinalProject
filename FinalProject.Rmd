---
title: "FinalProject"
author: "Zafir Momin"
date: "4/24/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir ="C:\\Users\\zafir\\Documents\\Text as Data\\Project\\eui-text-workshop\\datasets")
```

```{r echo=FALSE}
# import libraries
# rm(list=ls())

library(quanteda)
library(dplyr)

# Change to directory with csv
# setwd("C:\\Users\\zafir\\Documents\\Text as Data\\Project\\eui-text-workshop\\datasets")
```


```{r echo=TRUE}
tweets <- read.csv("candidate-tweets.csv", stringsAsFactors=F)
tweets$text <- gsub('https?://t.co/[A-Za-z0-9]+', '', tweets$text)
# tweets$candidate <- tweets$screen_name
tweets$candidate <- factor(tweets$screen_name, levels = unique(tweets$screen_name), labels = c(1, 2, 3, 4))

tweets <- tweets %>%  select(datetime, text, screen_name, candidate)
tweets$retweet <- 0
tweets$retweet[grep('RT @',tweets$text)] <- 1

tweets_NoRT <- tweets[grep(0, tweets$retweet),]
```

```{r echo=TRUE}
t_corpus <- corpus(tweets$text)

flesch_scores <- data.frame(textstat_readability(t_corpus, "Flesch"))

flesch_scores$screen_name <- tweets$screen_name

flesch_scores %>% group_by(screen_name) %>% summarise(Avg = mean(Flesch,na.rm=TRUE))


```



```{r echo=TRUE}
t_corpus <- corpus(tweets_NoRT$text)

flesch_scores <- data.frame(textstat_readability(t_corpus, "Flesch"))

flesch_scores$screen_name <- tweets_NoRT$screen_name

flesch_scores %>% group_by(screen_name) %>% summarise(Avg = mean(Flesch,na.rm=TRUE))

```




















