---
title: "FinalProject"
author: "Zafir Momin"
date: "4/24/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_knit$set(root.dir ="C:\\Users\\zafir\\Documents\\Text as Data\\Project\\eui-text-workshop\\datasets")
```

```{r echo=FALSE}
# import libraries
# rm(list=ls())

library(readr)
library(stringr)
library(quanteda)
library(dplyr)
library(quanteda.corpora)
library(tm)

# Change to directory with csv
# setwd("C:\\Users\\zafir\\Documents\\Text as Data\\Project\\eui-text-workshop\\datasets")
```


```{r echo=TRUE}
tweets <- read.csv("candidate-tweets.csv", stringsAsFactors=F)
tweets$text <- gsub('https?://t.co/[A-Za-z0-9]+', '', tweets$text)
# tweets$candidate <- tweets$screen_name
tweets$candidate <- factor(tweets$screen_name, levels = unique(tweets$screen_name), labels = c(1, 2, 3, 4))

tweets <- tweets %>%  select(datetime, text, screen_name, candidate)
tweets$retweet <- 0
tweets$retweet[grep('RT @',tweets$text)] <- 1
tweets$text <- gsub("amp", "", tweets$text) 
tweets$text <- stemDocument(tweets$text)
tweets$text = removeWords(tweets$text, stopwords("english"))
tweets$text = stripWhitespace(tweets$text)
tweets_NoRT <- tweets[grep(0, tweets$retweet),]
```

```{r echo=TRUE}

t_corpus <- corpus(tweets$text)

#t_corpus <- tolower(t_corpus)

flesch_scores <- data.frame(textstat_readability(t_corpus, "Flesch"))

flesch_scores$screen_name <- tweets$screen_name

flesch_scores %>% group_by(screen_name) %>% summarise(Avg = mean(Flesch,na.rm=TRUE))


```

```{r echo=TRUE}

t_corpus <- corpus(tweets_NoRT$text)

flesch_scores <- data.frame(textstat_readability(t_corpus, "Flesch"))

flesch_scores$screen_name <- tweets_NoRT$screen_name

flesch_scores %>% group_by(screen_name) %>% summarise(Avg = mean(Flesch,na.rm=TRUE))

```

```{r}
Trump_tweet <- ''
Trump <- tweets_NoRT[tweets_NoRT$candidate==1,]
for (i in 1:nrow(Trump)){
  Trump_tweet <- paste(Trump_tweet,Trump[i,2])
}
Clinton_tweet <- ''
Clinton <- tweets_NoRT[tweets_NoRT$candidate==2,]
for (i in 1:nrow(Clinton)){
  Clinton_tweet <- paste(Clinton_tweet,Clinton[i,2])
}
Cruz_tweet <- ''
Cruz <- tweets_NoRT[tweets_NoRT$candidate==3,]
for (i in 1:nrow(Cruz)){
  Cruz_tweet <- paste(Cruz_tweet,Cruz[i,2])
}
Sanders_tweet <- ''
Sanders <- tweets_NoRT[tweets_NoRT$candidate==4,]
for (i in 1:nrow(Cruz)){
  Sanders_tweet <- paste(Sanders_tweet,Sanders[i,2])
}

candidate_dfm <- dfm(c(Trump_tweet, Clinton_tweet,Cruz_tweet,Sanders_tweet))
similarity <- textstat_simil(candidate_dfm, margin = "documents", method = "cosine")
rownames(similarity) <- c('Trump','Clinton','Cruz','Sanders')
colnames(similarity) <- c('Trump','Clinton','Cruz','Sanders')
as.matrix(similarity)
```

```{r}
dtm <- TermDocumentMatrix(Corpus(VectorSource(c(Clinton_tweet,Sanders_tweet))))
matrix <- as.matrix(dtm) 
words <- sort(rowSums(matrix),decreasing=TRUE) 
df <- data.frame(word = names(words),freq=words)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,           max.words=70, random.order=FALSE, rot.per=0.1,            colors=brewer.pal(8, "Dark2"))
```
```{r}
dtm <- TermDocumentMatrix(Corpus(VectorSource(c(Cruz_tweet,Trump_tweet))))
matrix <- as.matrix(dtm) 
words <- sort(rowSums(matrix),decreasing=TRUE) 
df <- data.frame(word = names(words),freq=words)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,           max.words=70, random.order=FALSE, rot.per=0.1,            colors=brewer.pal(8, "Dark2"))


```


















